{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Notebook for extracting icebergs from DEMs\n",
    "\n",
    "by Jessica Scheick\n",
    "\n",
    "Workflow based on previous methods and code developed by JScheick for Scheick et al 2019 *Remote Sensing*.\n",
    "\n",
    "***Important note about CRS handling*** This code was developed while also learning about Xarray, rioxarray, rasterio, and other Python geospatial libraries. Since projections are not yet fully handled [smoothly] in any of those resources, and especially not integrated, there's little to no built in checking or handling of CRS. Instead, handling is done manually throughout the code and external to this notebook. This is critical to know because the CRS displayed by a rioxarray dataset may be from one variable added to the dataset, but is not necessarily the original (or read in) CRS for each variable in the dataset (hence the manual, external handling). The `get_mask` and `get_new_var_from_file` methods should reproject new data sources before adding them to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "import hvplot.xarray\n",
    "# import hvplot.pandas\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh','matplotlib')\n",
    "from holoviews import dim, opts\n",
    "import datetime as dt\n",
    "import os\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "import pyproj\n",
    "import rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import icebath as icebath\n",
    "from icebath.core import build_xrds\n",
    "from icebath.utils import raster_ops as raster_ops\n",
    "from icebath.utils import vector_ops as vector_ops\n",
    "from icebath.core import fl_ice_calcs as icalcs\n",
    "from icebath.core import build_gdf\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# laptop dask setup\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster, performance_report\n",
    "# cluster=LocalCluster()\n",
    "# client = Client(cluster) #, processes=False) this flag only works if you're not using a LocalCluster, in which case don't use `cluster` either\n",
    "client = Client(processes=True, n_workers=2, threads_per_worker=2, memory_limit='7GB', dashboard_address=':8787')\n",
    "client\n",
    "\n",
    "# Dask docs of interest\n",
    "# includes notes and tips on threads vs processes: https://docs.dask.org/en/latest/best-practices.html#best-practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pangeo dask setup\n",
    "from dask_gateway import GatewayCluster\n",
    "\n",
    "cluster = GatewayCluster()\n",
    "# options = cluster.gateway.cluster_options()\n",
    "# options\n",
    "# cluster.adapt(minimum=2, maximum=10)  # or cluster.scale(n) to a fixed size.\n",
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconnect to existing cluster\n",
    "from dask_gateway import Gateway\n",
    "g = Gateway()\n",
    "g.list_clusters()\n",
    "cluster = g.connect(g.list_clusters()[0].name)\n",
    "cluster\n",
    "cluster.scale(0)\n",
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client.get_versions(check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_mem():\n",
    "    from pympler import summary, muppy\n",
    "    all_objects = muppy.get_objects()\n",
    "    s = summary.summarize(all_objects)\n",
    "    return s\n",
    "\n",
    "s = client.run(debug_mem)\n",
    "\n",
    "from pympler import summary, muppy\n",
    "summary.print_(list(s.values())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in DEMs and apply corrections (tidal, geoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ilulissat Isfjord Mouth, resampled to 50m using CHANGES\n",
    "# ds = build_xrds.xrds_from_dir('/home/jovyan/icebath/notebooks/supporting_docs/Elevation/ArcticDEM/Regridded_50m_tiles/n69w052/', fjord=\"JI\")\n",
    "\n",
    "# Ilulissat Isfjord Mouth, original 2m (the files from CHANGES seem much smaller than those from Kane/Pennell. \n",
    "# data = xr.open_rasterio('/home/jovyan/icebath/notebooks/supporting_docs/Elevation/ArcticDEM/2m_tiles/n69w052/SETSM_W1W1_20100813_102001000E959700_102001000ECB6B00_seg1_2m_v3.0_dem.tif')\n",
    "ds = build_xrds.xrds_from_dir('/Users/jessica/projects/bathymetry_from_bergs/DEMs/2m/', fjord=\"JI\")\n",
    "# ds = build_xrds.xrds_from_dir('/Users/jessica/projects/bathymetry_from_bergs/DEMs/KaneW2W2/', fjord=\"KB\", metastr=\"_meta\", bitmask=True)\n",
    "# ds = build_xrds.xrds_from_dir('/home/jovyan/icebath/notebooks/supporting_docs/Elevation/ArcticDEM/2m_tiles/', fjord=\"JI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrolldem = ds['elevation'].hvplot.image(x='x', y='y',datashade=False, rasterize=True, aspect='equal', cmap='magma', dynamic=True,\n",
    "                       xlabel=\"x (km)\", ylabel=\"y (km)\", colorbar=True) #turn off datashade to see hover values + colorbar\n",
    "scrolldem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and Apply Land Mask\n",
    "**Note: requires a shapefile of the land areas in the ROI**\n",
    "\n",
    "The default is to use a shapefile of Greenland: `shpfile='/home/jovyan/icebath/notebooks/supporting_docs/Land_region.shp'`, but an alternative file can be specified.\n",
    "\n",
    "Underlying code is based on: https://gis.stackexchange.com/questions/357490/mask-xarray-dataset-using-a-shapefile\n",
    "Other results used rioxarray (which isn't on my current working environment), and my previous work did it all manually with gdal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.bergxr.get_mask(req_dim=['x','y'], req_vars=None, name='land_mask', \n",
    "#                    shpfile='/home/jovyan/icebath/notebooks/supporting_docs/Land_region.shp')\n",
    "                 shpfile='/Users/jessica/mapping/shpfiles/Greenland/Land_region/Land_region.shp')\n",
    "# ds.land_mask.plot()\n",
    "ds['elevation'] = ds['elevation'].where(ds.land_mask == True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Geoid Correction\n",
    "ArcticDEMs come as ellipsoidal height. They are corrected to geoidal height according to geoid_ht = ellipsoid - geoid_offset where geoid_offset is taken from BedMachine v3 and resampled in Xarray (using default \"linear\" interpolation for multidimensional arrays) to the resolution and extent of the region's dataset.\n",
    "\n",
    "BedMachine is now available on Pangeo via intake thanks to the Lahmont-Doherty Glaciology group.\n",
    " - Basic info: https://github.com/ldeo-glaciology/pangeo-bedmachine\n",
    " - Pangeo gallery glaciology examples: http://gallery.pangeo.io/repos/ldeo-glaciology/pangeo-glaciology-examples/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = ds.bergxr.to_geoid(source='/Users/jessica/mapping/datasets/160281892/BedMachineGreenland-2017-09-20_3413_'+ds.attrs['fjord']+'.nc')\n",
    "# ds = ds.bergxr.to_geoid(source='/home/jovyan/icebath/notebooks/supporting_docs/160281892/BedMachineGreenland-2017-09-20_'+ds.attrs['fjord']+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Tidal Correction\n",
    "\n",
    "Uses Tyler Sutterly's pyTMD library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path='/home/jovyan/pyTMD/models'\n",
    "model_path='/Users/jessica/computing/tidal_model_files'\n",
    "ds=ds.bergxr.tidal_corr(loc=[ds.attrs[\"fjord\"]], model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test to make sure that if you already have a tidal correction it won't reapply it, and test that it will return the tides if you don't have an elevation entered\n",
    "# ds=ds.bergxr.tidal_corr(loc=[\"JI\"])\n",
    "# ds=ds.bergxr.tidal_corr(loc=[\"JI\"]) # results in assertion error\n",
    "\n",
    "# ds.attrs['offset_names'] = ('random')\n",
    "# ds=ds.bergxr.tidal_corr(loc=[\"JI\"]) # results in longer attribute list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # go directly to icalcs function, called under the hood above, if you want to see plots\n",
    "# tides = icalcs.predict_tides(loc='JI',img_time=ds.dtime.values[0], model_path='/home/jovyan/pyTMD/models',\n",
    "#                     model='AOTIM-5-2018', epsg=3413, plot=True)\n",
    "# tides[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Icebergs from DEM and put into Geodataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completely automated iceberg delineation in the presence of clouds and/or data gaps (as is common in a DEM) is not yet easily implemented with existing methods. Many techniques have been refined for specific fjords or types of situations. Here, we tailor our iceberg detection towards icebergs that will provide reliable water depth estimates. The following filters are applied during the iceberg extraction process:\n",
    " - a minimum iceberg horizontal area is specified on a per-fjord basis. These minima are based on icebergs used to infer bathymetry in previous work (Scheick et al 2019).\n",
    " - a maximum allowed height for the median freeboard is specified on a per-fjord basis. These maxima are determined as 10% of the [largest] grounded ice thickness for the source glaciers. While the freeboard values from the DEM are later filtered to remove outliers in determining water depth, this filtering step during the delineation process removes \"icebergs\" where low clouds, rather than icebergs, are the surface represented in the DEM.\n",
    " - a maximum iceberg horizontal area of 1000000 m2 (1km2) is assumed to eliminate large clusters of icebergs, melange, and/or cloud picked up by the delineation algorithm.\n",
    " - the median freeboard must be greater than 15 m relative to [adjusted] sea level. If not, we can assume the iceberg is either a false positive (e.g. cloud or sea ice) or too small to provide a meaningful water depth estimate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "gdf = gpd.read_file('/Users/jessica/projects/bathymetry_from_bergs/prelim_results/JIicebergs.gpkg', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%prun\n",
    "# %%timeit -n 1 -r 1\n",
    "# 3min 17s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
    "# gdf=None\n",
    "gdf = build_gdf.xarray_to_gdf(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gdf.loc[((gdf['sl_adjust']>4.27) & (gdf['sl_adjust']<4.36))].groupby('date').berg_poly.plot()\n",
    "gdf.groupby('date').berg_poly.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This requires geoviews[http://geoviews.org/] be installed, and their install pages have warning if your environment uses [non] conda-forge\n",
    "# libraries and it won't resolve the environment with a conda install, so I'll need to create a new test env to try this\n",
    "# bergs = gdf.hvplot()\n",
    "# bergs\n",
    "# xarray-leaflet may be another good option to try: https://github.com/davidbrochart/xarray_leaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrolldems*bergs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Water Depths on Icebergs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.berggdf.calc_filt_draft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.berggdf.calc_rowwise_medmaxmad('filtered_draft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.berggdf.wat_depth_uncert('filtered_draft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mmm(vals): # mmm = min, med, max\n",
    "#     print(np.nanmin(vals))\n",
    "#     print(np.nanmedian(vals))\n",
    "#     print(np.nanmax(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract measured values from BedMachine v3 and IBCAOv4 (where available)\n",
    "All bathymetry values from these gridded products are included, then later parsed into bathymetric observations and inferred (from e.g. gravimetry, modeling) for comparing with iceberg-inferred water depths.\n",
    "\n",
    "Note that the datasets are subset to the region of the fjord outside this script to reduce memory requirements during processing.\n",
    "\n",
    "***Improvement: add CRS handling/checks to catch when a measurement dataset is incompatible and needs to be reprojected***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BedMachine Greenland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fjord = \"JI\"\n",
    "# measfile='/Users/jessica/mapping/datasets/160281892/BedMachineGreenland-2017-09-20.nc'\n",
    "measfile='/Users/jessica/mapping/datasets/160281892/BedMachineGreenland-2017-09-20_3413_'+fjord+'.nc'\n",
    "# measfile='/home/jovyan/icebath/notebooks/supporting_docs/160281892/BedMachineGreenland-2017-09-20.nc'\n",
    "# measfile='/home/jovyan/icebath/notebooks/supporting_docs/160281892/BedMachineGreenland-2017-09-20_'+ds.attrs['fjord']+'.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IBCAOv4\n",
    "https://www.gebco.net/data_and_products/gridded_bathymetry_data/arctic_ocean/\n",
    "\n",
    "Source keys: https://www.gebco.net/data_and_products/gridded_bathymetry_data/gebco_2020/\n",
    "\n",
    "Downloaded Feb 2021\n",
    "\n",
    "**NOTE** IBCAO has it's own Polar Stereo projection (EPSG:3996: WGS 84/IBCAO Polar Stereographic) so it needs to be reprojected before being applied to these datasets.\n",
    "See: https://spatialreference.org/ref/?search=Polar+Stereographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measfile2a='/Users/jessica/mapping/datasets/IBCAO_v4_200m_ice_3413.nc'\n",
    "# measfile2a='/Users/jessica/mapping/datasets/IBCAO_v4_200m_ice_3413_'+fjord+'.nc'\n",
    "# measfile2a='/home/jovyan/icebath/notebooks/supporting_docs/IBCAO_v4_200m_ice_3413.nc'\n",
    "# measfile2a='/home/jovyan/icebath/notebooks/supporting_docs/IBCAO_v4_200m_ice_3413_'+ds.attrs['fjord']+'.nc'\n",
    "measfile2b='/Users/jessica/mapping/datasets/IBCAO_v4_200m_TID_3413.nc'\n",
    "# measfile2b='/home/jovyan/icebath/notebooks/supporting_docs/IBCAO_v4_200m_TID_3413.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.berggdf.get_meas_wat_depth([measfile, measfile2a, measfile2b], \n",
    "                               vardict={\"bed\":\"bmach_bed\", \"errbed\":\"bmach_errbed\", \"source\":\"bmach_source\",\n",
    "                                       \"ibcao_bathy\":\"ibcao_bed\", \"z\":\"ibcao_source\"},\n",
    "                               nanval=-9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf #[gdf['date'].dt.year.astype(int)==2016]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the measured and inferred values\n",
    "Plots the gridded versus iceberg-freeboard-inferred values for all icebergs relative to the values in BedMachine and IBCAO.\n",
    "\n",
    "Left plot shows measured values within the gridded datasets; right plot show the modeled/inferred values within the gridded data products (hence the larger error bars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icebath.utils import plot as ibplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibplot.meas_vs_infer_fig(gdf, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the iceberg outlines and data to a geopackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shpgdf = gdf.copy(deep=True)\n",
    "\n",
    "del shpgdf['DEMarray']\n",
    "del shpgdf['filtered_draft']\n",
    "\n",
    "shpgdf.to_file(\"/Users/jessica/projects/bathymetry_from_bergs/prelim_results/JIbergs_faster.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the iceberg outlines and data to a shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shpgdf = gdf.copy(deep=True)\n",
    "shpgdf['year'] = shpgdf['date'].dt.year.astype(int)\n",
    "\n",
    "del shpgdf['date']\n",
    "del shpgdf['DEMarray']\n",
    "del shpgdf['filtered_draft']\n",
    "\n",
    "# NOTE: need to rename columns due to name length limits for shapefile; otherwise,\n",
    "# all ended up as \"filtered_#\"\n",
    "\n",
    "shpgdf.to_file(\"/Users/jessica/projects/bathymetry_from_bergs/prelim_results/icebergs_JI.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Iceberg Outlines for a Single DEM\n",
    "Some attempts at doing this with Holoviews, including to try and have it with a slider bar, are in the misc_dev_notes_notebook. As it stands currently, this implementation should work but is quite slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timei=1\n",
    "print(ds['dtime'].isel({'dtime':timei}))\n",
    "dem = ds.isel({'dtime':timei})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = dem.elevation.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot objectives: show DEM, land mask, iceberg outlines. 2nd plot with just orig DEM?\n",
    "fig = plt.figure(figsize=(12,12)) # width, height in inches\n",
    "# gs = gridspec.GridSpec(ncols=1, nrows=2, figure=fig)\n",
    "gs=fig.add_gridspec(3,1, hspace=0.3) # nrows, ncols\n",
    "\n",
    "# DEM plot\n",
    "axDEM = plt.subplot(gs[0:2,0])\n",
    "dem.elevation.plot.pcolormesh(ax=axDEM, \n",
    "                              vmin=-10, vmax=75, cmap='magma', # vmin and vmax set the colorbar limits here\n",
    "                              xscale='linear', yscale='linear',\n",
    "                              cbar_kwargs={'label':\"Elevation (m amsl)\"})\n",
    "\n",
    "# land mask\n",
    "landcm = mpl.colors.ListedColormap([(0.5, 0.35, 0.35, 1.), (0.5, 0., 0.6, 0)])\n",
    "dem.land_mask.plot(ax=axDEM, cmap=landcm, add_colorbar=False)\n",
    "\n",
    "# iceberg contours - ultimately add this from geodataframe\n",
    "# dem.elevation.plot.contour(ax=axDEM, levels=[threshold], colors=['gray'])\n",
    "# Note: dem.elevation.plot.contour(levels=[threshold], colors=['gray']) will show the plot, but you can't\n",
    "# add it to these axes and then show it inline from a second cell\n",
    "# I'm not entirely sure this is plotting what I think; it's also not actually plotting the contoured data \n",
    "gdf.loc[gdf['date']==ds.dtime.isel({'dtime':timei}).values].berg_poly.plot(ax=axDEM,\n",
    "                                                                          linestyle='-',\n",
    "                                                                          linewidth=2,\n",
    "                                                                          edgecolor='gray',\n",
    "                                                                          facecolor=(0,0,0,0))\n",
    "\n",
    "\n",
    "xmin = -250000\n",
    "xmax = -232750\n",
    "ymin = -2268250\n",
    "ymax = -2251000\n",
    "# xmin = -235000 #zoom in to figure out empty iceberg DEM during gdf generation\n",
    "# xmax = -233000\n",
    "# ymin = -2257500\n",
    "# ymax = -2255000\n",
    "while (xmin-xmax) != (ymin-ymax):\n",
    "    print(\"modify your x and y min/max to make the areas equal\")\n",
    "    break\n",
    "    \n",
    "axDEM.set_aspect('equal')\n",
    "axDEM.set_xlim(xmin, xmax)\n",
    "axDEM.set_ylim(ymin, ymax)\n",
    "\n",
    "axDEM.set_xlabel(\"x (km)\")\n",
    "axDEM.set_ylabel(\"y (km)\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note: gdf['date']==timei is returning all false, so the datetimes will need to be dealt with to get the areas from the geometry column\n",
    "# areas = gdf.loc[:, gdf['date']==timei].geometry.area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
